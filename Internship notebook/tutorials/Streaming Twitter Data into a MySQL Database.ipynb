{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streaming Twitter Data into a MySQL Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial session , I wanted to look at how we can use python and an API to stream data directly into a MySQL database.\n",
    "We are going to be using the Twitter API to search for tweets containing specific keywords and stream this directly into our database. Once we have done this, the data will be available for further analysis at any time. This task requires a few things:\n",
    "1. A Twitter account and API credentials\n",
    "2. A MySQL database\n",
    "3. The Tweepy and mysql-connector Python Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter API\n",
    "Before we access the API you need to set up a twitter app. I won’t do an in-depth tutorial on this but briefly, you need to do the following:\n",
    "* go to the following website https://developer.twitter.com/ and create an account. (This step is a bit more involved then it used to be and involves providing a brief summary of what you intend to do with the tweets and what they will be used for. I believe it has something to do with new EU privacy laws.)\n",
    "* Once you have verified your email you can log into your account. You should be able to create a new app on the following webpage: https://developer.twitter.com/en/apps\n",
    "* Fill in all the details about your app and then create your access token.Make a note of your consumer key, consumer secret, OAuth access token and OAuth access token secret. These are needed to connect to the API.\n",
    "For a more complete tutorial on this, I suggest this blog post. After these steps, our app is now able to connect to the Twitter streaming API provided we write the correct code. Next up, I will go through setting up the MySQL database so we have somewhere to store all of our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MySQL Workbench\n",
    "\n",
    "There are many different types of databases we could use for this particular task including NoSQL databases such as MongoDB or Redis. I have, however, chosen to use MySQL as it is still one of the most popular databases out there. Before we begin, we will need to install MySQL Workbench and MySQL server. [Here](https://www.youtube.com/watch?v=iOlJxOkp6sI) is a video tutorial explaining how to install both and set everything up to start collecting the data.\n",
    "\n",
    "Once you have finished the tutorial above, you should have a connection and a schema/database set up (My database is imaginatively called twitterdb). After we have set up MySQL workbench and are somewhat familiar with the interface, we can finally create a table to store our twitter data. Creating a table is very straightforward and we can use the UI or even use queries. Using the UI we just right click on our database and click create a table. We can then input our column names and data types directly. At this point, it is worth thinking about the data we want to store and what kind of data types they will be. To get a better understanding of the data types we need we should take a peek at the TwitterAPI [documentation](https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/intro-to-tweet-json). Essentially I want the **username** of the person who wrote the tweet, the **time** it was created, the **tweet**, the **retweet count**, the **place** the tweet originated and the **location** (more on these below). This corresponds to 6 columns plus the **primary key** and we can define the datatypes as follows:\n",
    "\n",
    "* primary key: INT(11)\n",
    "* username: VARCHAR(255)\n",
    "* created_at: VARCHAR(45)\n",
    "* tweet: TEXT\n",
    "* retweet_count: INT(11)\n",
    "* location: VARCHAR(100)\n",
    "* place: VARCHAR(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python\n",
    "OK now that we have our database set up, its’ time to jump into the Python code. There are a few things we want our code to do:\n",
    "1. We want to create a class that allows us to connect to the Twitter API.\n",
    "2. We also need to create some code that connects to our database and reads the data into the correct columns.\n",
    "We are going to be using the Tweepy library which will make it very easy for us to connect to the API and start streaming the data. Before we start, we are again going to look at some delicious [documentation](https://tweepy.readthedocs.io/en/v3.5.0/). In the Tweepy documentation, we can find some really useful examples of the classes and methods we need to use to interact with the API. The code below is a simple example that allows us to connect to the API and print tweets from our timeline:\n",
    "\n",
    "```\n",
    "import tweepy\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth)\n",
    "public_tweets = api.home_timeline()\n",
    "for tweet in public_tweets:\n",
    "    print(tweet.text)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, so hopefully this is pretty straightforward. It looks like we just need to set our credentials, access the timeline and loop through it to print it out. What we want to do is a bit different. We want to stream live tweets into our database and according to the documentation, need to do the following three things:\n",
    "* Create a class inheriting from StreamListener.\n",
    "* Instantiate an object from this class.\n",
    "* Use this object to connect to the API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems straightforward enough. Lets see how we do this in Python (**Full code at end of post**). We need to import some libraries and also to set our tokens and secret keys and our password for the database. you can save all of these in the **setting.sh** file which gets called using the code below and sets the tokens and keys as environment variables.\n",
    "```\n",
    "subprocess.call(“./settings.sh”, shell=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in our imports, we need **mysql-connector**. Again, here is some useful examples of how the library works. We can install any libraries that we don’t have using the pip command. We should then be able to import these libraries from our script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next up, we need to set up our class inheriting from StreamListener. We are going to give the class three methods. These are methods that the class already implements which we are going to override. The code below implements this.\n",
    "\n",
    "Let’s go through this step by step to make sure everything is clear. The first method, on_connect() simply notifies us when we are connected to the stream. The on_error() method prints an error whenever our HTTP status code is not 200 (200 means everything worked). List of codes for those interested: https://en.wikipedia.org/wiki/List_of_HTTP_status_codes\n",
    "\n",
    "OK, the next method, on_data() is a little more complex. To understand this we will need to know a little bit more about the structure of the tweets. When we access the API we are getting a JSON response (very similar structure to a python dictionary). More info here.\n",
    "Essentially our tweet object that is returned looks something like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "{ “created_at”:”Thu Apr 06 15:24:15 +0000 2017\", \n",
    "  “id”: 850006245121695744, \n",
    "  “id_str”: “850006245121695744”, \n",
    "  “text”: “1/ Today we’re sharing our vision for the future of the    Twitter API platform!nhttps://t.co/XweGngmxlP\", \n",
    "  “user”: {}, \n",
    "  “entities”: {} }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have a JSON object which contains key, value pairs (note there are a few attributes not listed here that we will use). So what data do we actually want from this? There is actually quite a lot of information available from the tweet object and I recommend going through the documentation to see what attributes might interest you. For this analysis I chose to collect data on the username, the time the tweet was created (this is more useful if we collect tweets over time), the actual tweet, the country of the tweet, the location (which is more local) and finally the retweet count and this is reflected in the code above.\n",
    "\n",
    "The final few lines call the **connect()** method which takes our variables as parameters. This code is all wrapped in a try, except statement to catch any errors, we may run into.\n",
    "\n",
    "Alright, you may have noticed that we haven’t created the **connect()** method yet so let’s create it. This method is not surprisingly, going to connect to our database and feed in all the data. As I said before, the method takes in our variables created in the **on_data()** method of the StreamListener class as arguments and inserts them into the columns of the same name in our database. To connect to our database we simply use the **connector.connect** method and pass in our database info which we can find from MySQL workbench. If our connection was successful, a cursor object is created allowing us to execute SQL statements. \n",
    "\n",
    "Now we can write our query and insert the data into the correct table in our **twitterdb** database using the execute command. While is_connected() is true our database connection stays open and continually feeds the data into the database until we kill it in the terminal (using Ctrl+C).\n",
    "We can create a list of words that we want to filter the stream for. I am a bit of a golf fan so I decided to search for words relating to golf. In practice, you can put whatever you want in this list.\n",
    "\n",
    "Now we just need to set up our script to call these functions when we execute the file from the terminal. To access the API we need to pass our credentials as arguments to the **OAuthHandler** method and the **set_access_token** method. Next, we create the stream by passing in our verified api object and our listener. We can also create our list of words to **filter** for here. To start the stream we simply call the filter method on our stream object and pass in our list of words as an argument. I saved this script as **StreamSQL.py**.\n",
    "\n",
    "If we want to run this code and start collecting tweets we can use the terminal. One important thing to note here is that we need to make sure our SQL server is up and running for the script to work so it is worth double checking this before we run the script.\n",
    "\n",
    "We can open a terminal directly from the folder where we stored the script and simply type:\n",
    "```\n",
    "python StreamSQL.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "import tweepy\n",
    "import json\n",
    "from dateutil import parser\n",
    "import time\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "#importing file which sets env variable\n",
    "subprocess.call(\"./settings.sh\", shell = True)\n",
    "\n",
    "\n",
    "consumer_key = os.environ['CONSUMER_KEY']\n",
    "consumer_secret = os.environ['CONSUMER_SECRET']\n",
    "access_token = os.environ['ACCESS_TOKEN']\n",
    "access_token_secret = os.environ['ACCESS_TOKEN_SECRET']\n",
    "password = os.environ['PASSWORD']\n",
    "\n",
    "\n",
    "def connect(username, created_at, tweet, retweet_count, place , location):\n",
    "    \"\"\"\n",
    "    connect to MySQL database and insert twitter data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        con = mysql.connector.connect(host = 'localhost',\n",
    "        database='twitterdb', user='root', password = password, charset = 'utf8')\n",
    "        \n",
    "\n",
    "        if con.is_connected():\n",
    "            \"\"\"\n",
    "            Insert twitter data\n",
    "            \"\"\"\n",
    "            cursor = con.cursor()\n",
    "            # twitter, golf\n",
    "            query = \"INSERT INTO Golf (username, created_at, tweet, retweet_count,place, location) VALUES (%s, %s, %s, %s, %s, %s)\"\n",
    "            cursor.execute(query, (username, created_at, tweet, retweet_count, place, location))\n",
    "            con.commit()\n",
    "            \n",
    "            \n",
    "    except Error as e:\n",
    "        print(e)\n",
    "\n",
    "    cursor.close()\n",
    "    con.close()\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "# Tweepy class to access Twitter API\n",
    "class Streamlistener(tweepy.StreamListener):\n",
    "    \n",
    "\n",
    "    def on_connect(self):\n",
    "        print(\"You are connected to the Twitter API\")\n",
    "\n",
    "\n",
    "    def on_error(self):\n",
    "        if status_code != 200:\n",
    "            print(\"error found\")\n",
    "            # returning false disconnects the stream\n",
    "            return False\n",
    "\n",
    "    \"\"\"\n",
    "    This method reads in tweet data as Json\n",
    "    and extracts the data we want.\n",
    "    \"\"\"\n",
    "    def on_data(self,data):\n",
    "        \n",
    "        try:\n",
    "            raw_data = json.loads(data)\n",
    "\n",
    "            if 'text' in raw_data:\n",
    "                \n",
    "                username = raw_data['user']['screen_name']\n",
    "                created_at = parser.parse(raw_data['created_at'])\n",
    "                tweet = raw_data['text']\n",
    "                retweet_count = raw_data['retweet_count']\n",
    "\n",
    "                if raw_data['place'] is not None:\n",
    "                    place = raw_data['place']['country']\n",
    "                    print(place)\n",
    "                else:\n",
    "                    place = None\n",
    "                \n",
    "\n",
    "                location = raw_data['user']['location']\n",
    "\n",
    "                #insert data just collected into MySQL database\n",
    "                connect(username, created_at, tweet, retweet_count, place, location)\n",
    "                print(\"Tweet colleted at: {} \".format(str(created_at)))\n",
    "        except Error as e:\n",
    "            print(e)\n",
    "\n",
    "\n",
    "if __name__== '__main__':\n",
    "\n",
    "    # # #Allow user input\n",
    "    # track = []\n",
    "    # while True:\n",
    "\n",
    "    # input1  = input(\"what do you want to collect tweets on?: \")\n",
    "    # track.append(input1)\n",
    "\n",
    "    # input2 = input(\"Do you wish to enter another word? y/n \")\n",
    "    # if input2 == 'n' or input2 == 'N':\n",
    "    #     break\n",
    "    \n",
    "    # print(\"You want to search for {}\".format(track))\n",
    "    # print(\"Initialising Connection to Twitter API....\")\n",
    "    # time.sleep(2)\n",
    "\n",
    "    # authentification so we can access twitter\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_token_secret)\n",
    "    api =tweepy.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "    # create instance of Streamlistener\n",
    "    listener = Streamlistener(api = api)\n",
    "    stream = tweepy.Stream(auth, listener = listener)\n",
    "\n",
    "    track = ['golf', 'masters', 'reed', 'mcilroy', 'woods']\n",
    "    #track = ['nba', 'cavs', 'celtics', 'basketball']\n",
    "    # choose what we want to filter by\n",
    "    stream.filter(track = track, languages = ['en'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
